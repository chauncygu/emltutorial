{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning a Neural Network\n",
    "\n",
    "Now, let's actually try to learn a ML model: as a first example, we will consider neural networks and train them using [keras](https://keras.io) and [TensorFlow](https://www.tensorflow.org)\n",
    "\n",
    "Given our input data (i.e. edge ratio, infection probability and so on) we want to predict the number of zombies and survivors. In other words: we have a regression task.\n",
    "\n",
    "Let's start by loading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data_fname = os.path.join('shared', 'za_processed.h5')\n",
    "with pd.HDFStore(data_fname) as store:\n",
    "    data_tr = store['data_tr']\n",
    "    data_vl = store['data_vl']\n",
    "    data_ts = store['data_ts']\n",
    "    means_in = store['means_in']\n",
    "    stds_in = store['stds_in']\n",
    "    sim_in = store['sim_in']\n",
    "    sim_out = store['sim_out']\n",
    "    in_defaults = store['in_defaults']\n",
    "    pop_size = store['meta']['pop_size']\n",
    "\n",
    "data_tr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separating Input and Output\n",
    "\n",
    "Since we stored the series of input and output attributes, it is fairly easy to separate out data and have it ready for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate input and output\n",
    "X_tr = data_tr[sim_in]\n",
    "Y_tr = data_tr[sim_out]\n",
    "X_vl = data_vl[sim_in]\n",
    "Y_vl = data_vl[sim_out]\n",
    "X_ts = data_ts[sim_in]\n",
    "Y_ts = data_ts[sim_out]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Networks\n",
    "\n",
    "We are now ready to learn a ML model: we will start by training a network for each type of output (zombies and survivors), using the keras `Sequential` API.\n",
    "\n",
    "Our loss function will be the Mean Squared Error (as it is often the case for regression problems) and we will also evaluate our networks using the R2 score (i.e. coefficient of determination).\n",
    "\n",
    "We will use a simple callback to stop trainig if no improvement is reported on the validation set for a number of iterations, and a second callback to store the best model on a pair of files.\n",
    "\n",
    "For more information about how to use all these components, see [the keras documentation](https://keras.io/getting-started/sequential-model-guide/)\n",
    "\n",
    "Let's start with a very simple, linear model (if we are lucky it may be enough):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import backend as K\n",
    "import tensorflow\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Seed the RNGs\n",
    "np.random.seed(42)\n",
    "tensorflow.set_random_seed(42)\n",
    "\n",
    "# Custom R2 metric (courtesy of https://www.kaggle.com/c/mercedes-benz-greener-manufacturing/discussion/34019)\n",
    "def r2_score(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "# Input shape\n",
    "input_shape = (X_tr.shape[1],)\n",
    "\n",
    "# Handle the two outputs\n",
    "max_epochs = 50\n",
    "for target in sim_out:\n",
    "    y_tr = Y_tr[target].values\n",
    "    y_vl = Y_vl[target].values\n",
    "    y_ts = Y_ts[target].values\n",
    "\n",
    "    # Define a Neural Network model to predict the number of infected\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1, activation='linear', input_shape=input_shape))\n",
    "\n",
    "    # Compile\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='mse',\n",
    "                  metrics=[r2_score])\n",
    "\n",
    "    # Setup and perform training\n",
    "    weight_fname = os.path.join('shared', 'nn_reg_%s.h5' % target)\n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience=5),\n",
    "                 ModelCheckpoint(filepath=weight_fname, monitor='val_loss', save_best_only=True)]\n",
    "    model.fit(X_tr, y_tr, epochs=max_epochs, batch_size=32, callbacks=callbacks,\n",
    "              validation_data=(X_vl, y_vl), verbose=0)\n",
    "    \n",
    "    # Save the model architecture\n",
    "    arch_fname = os.path.join('shared', 'nn_reg_%s.json' % target)\n",
    "    with open(arch_fname, 'w') as fp:\n",
    "        fp.write(model.to_json())\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    print('=== Results for target \"{}\"'.format(target))\n",
    "    res_tr = model.evaluate(X_tr, y_tr, batch_size=len(X_tr))\n",
    "    print('Loss and R2 on the training set: {}, {}'.format(*res_tr))\n",
    "    res_vl = model.evaluate(X_vl, y_vl, batch_size=len(X_vl))\n",
    "    print('Loss and R2 on the validation set: {}, {}'.format(*res_vl) )\n",
    "    res_ts = model.evaluate(X_ts, y_ts, batch_size=len(X_ts))\n",
    "    print('Loss and R2 on the test set: {}, {}'.format(*res_ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not particualarly good... Let's stack more layers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import backend as K\n",
    "import tensorflow\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Seed the RNGs\n",
    "np.random.seed(42)\n",
    "tensorflow.set_random_seed(42)\n",
    "\n",
    "# Custom R2 metric (courtesy of https://www.kaggle.com/c/mercedes-benz-greener-manufacturing/discussion/34019)\n",
    "def r2_score(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "# Input shape\n",
    "input_shape = (X_tr.shape[1],)\n",
    "\n",
    "# Handle the two outputs\n",
    "max_epochs = 50\n",
    "for target in sim_out:\n",
    "    y_tr = Y_tr[target].values\n",
    "    y_vl = Y_vl[target].values\n",
    "    y_ts = Y_ts[target].values\n",
    "\n",
    "    # Define a Neural Network model to predict the number of infected\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, activation='relu', input_shape=input_shape))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    # Compile\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='mse',\n",
    "                  metrics=[r2_score])\n",
    "\n",
    "    # Setup and perform training\n",
    "    weight_fname = os.path.join('shared', 'nn_reg_%s.h5' % target)\n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience=5),\n",
    "                 ModelCheckpoint(filepath=weight_fname, monitor='val_loss', save_best_only=True)]\n",
    "    model.fit(X_tr, y_tr, epochs=max_epochs, batch_size=32, callbacks=callbacks,\n",
    "              validation_data=(X_vl, y_vl), verbose=0)\n",
    "    \n",
    "    # Save the model architecture\n",
    "    arch_fname = os.path.join('shared', 'nn_reg_%s.json' % target)\n",
    "    with open(arch_fname, 'w') as fp:\n",
    "        fp.write(model.to_json())\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    print('=== Results for target \"{}\"'.format(target))\n",
    "    res_tr = model.evaluate(X_tr, y_tr, batch_size=len(X_tr))\n",
    "    print('Loss and R2 on the training set: {}, {}'.format(*res_tr))\n",
    "    res_vl = model.evaluate(X_vl, y_vl, batch_size=len(X_vl))\n",
    "    print('Loss and R2 on the validation set: {}, {}'.format(*res_vl) )\n",
    "    res_ts = model.evaluate(X_ts, y_ts, batch_size=len(X_ts))\n",
    "    print('Loss and R2 on the test set: {}, {}'.format(*res_ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import backend as K\n",
    "import tensorflow\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Seed the RNGs\n",
    "np.random.seed(42)\n",
    "tensorflow.set_random_seed(42)\n",
    "\n",
    "# Custom R2 metric (courtesy of https://www.kaggle.com/c/mercedes-benz-greener-manufacturing/discussion/34019)\n",
    "def r2_score(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "# Input shape\n",
    "input_shape = (X_tr.shape[1],)\n",
    "\n",
    "# Handle outputs\n",
    "max_epochs = 50\n",
    "for target in sim_out:\n",
    "    y_tr = Y_tr[target].values\n",
    "    y_vl = Y_vl[target].values\n",
    "    y_ts = Y_ts[target].values\n",
    "\n",
    "    # Define a Neural Network model to predict the number of infected\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, activation='relu', input_shape=input_shape))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    # Compile\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='mse',\n",
    "                  metrics=[r2_score])\n",
    "\n",
    "    # Setup and perform training\n",
    "    weight_fname = os.path.join('shared', 'nn_reg_%s.h5' % target)\n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience=5),\n",
    "                 ModelCheckpoint(filepath=weight_fname, monitor='val_loss', save_best_only=True)]\n",
    "    model.fit(X_tr, y_tr, epochs=max_epochs, batch_size=32, callbacks=callbacks,\n",
    "              validation_data=(X_vl, y_vl), verbose=0)\n",
    "    \n",
    "    # Save the model architecture\n",
    "    arch_fname = os.path.join('shared', 'nn_reg_%s.json' % target)\n",
    "    with open(arch_fname, 'w') as fp:\n",
    "        fp.write(model.to_json())\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    print('=== Results for target \"{}\"'.format(target))\n",
    "    res_tr = model.evaluate(X_tr, y_tr, batch_size=len(X_tr))\n",
    "    print('Loss and R2 on the training set: {}, {}'.format(*res_tr))\n",
    "    res_vl = model.evaluate(X_vl, y_vl, batch_size=len(X_vl))\n",
    "    print('Loss and R2 on the validation set: {}, {}'.format(*res_vl) )\n",
    "    res_ts = model.evaluate(X_ts, y_ts, batch_size=len(X_ts))\n",
    "    print('Loss and R2 on the test set: {}, {}'.format(*res_ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems we have reached a plateau, but we are still not doing well.\n",
    "\n",
    "What happened?\n",
    "\n",
    "Well, several things. Let's start with one of them..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Correlations\n",
    "\n",
    "The two outputs that we care about (zombies and survivors) are quite obviously correlated. In case of no deaths, their sum is always necessarily equal to the total population, i.e. 500 individuals (or 1, after the normalization).\n",
    "\n",
    "By learning individual models for the two outputs, we are failing to provide the network with this information.\n",
    "\n",
    "We can try and address this issue by predicting **both outputs at the same time**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import backend as K\n",
    "import tensorflow\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Seed the RNGs\n",
    "np.random.seed(42)\n",
    "tensorflow.set_random_seed(42)\n",
    "\n",
    "# Custom R2 metric (courtesy of https://www.kaggle.com/c/mercedes-benz-greener-manufacturing/discussion/34019)\n",
    "def r2_score(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "# Input shape\n",
    "input_shape = (X_tr.shape[1],)\n",
    "\n",
    "# Both outputs at the same time\n",
    "max_epochs = 50\n",
    "\n",
    "# Define a Neural Network model to predict the number of infected\n",
    "model = Sequential()\n",
    "model.add(Dense(16, activation='relu', input_shape=input_shape))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(2, activation='linear'))\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mse',\n",
    "              metrics=[r2_score])\n",
    "\n",
    "# Setup and perform training\n",
    "weight_fname = os.path.join('shared', 'nn_reg.h5')\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=5),\n",
    "             ModelCheckpoint(filepath=weight_fname, monitor='val_loss', save_best_only=True)]\n",
    "model.fit(X_tr, Y_tr, epochs=max_epochs, batch_size=32, callbacks=callbacks,\n",
    "          validation_data=(X_vl, Y_vl), verbose=0)\n",
    "\n",
    "# Save the model architecture\n",
    "arch_fname = os.path.join('shared', 'nn_reg.json')\n",
    "with open(arch_fname, 'w') as fp:\n",
    "    fp.write(model.to_json())\n",
    "\n",
    "# Evaluate on the test set\n",
    "res_tr = model.evaluate(X_tr, Y_tr, batch_size=len(X_tr))\n",
    "print('Loss and R2 on the training set: {}, {}'.format(*res_tr))\n",
    "res_vl = model.evaluate(X_vl, Y_vl, batch_size=len(X_vl))\n",
    "print('Loss and R2 on the validation set: {}, {}'.format(*res_vl) )\n",
    "res_ts = model.evaluate(X_ts, Y_ts, batch_size=len(X_ts))\n",
    "print('Loss and R2 on the test set: {}, {}'.format(*res_ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerably better! But still not particularly good.\n",
    "\n",
    "What is going on? Let's go back to the drawing board, i.e. to the data pre-processing step."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
