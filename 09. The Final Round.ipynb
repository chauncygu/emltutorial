{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Final Round\n",
    "\n",
    "We can finally solve again the problem, with the new networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import importlib\n",
    "\n",
    "# Dynamically add the Empirical Model Learning folder to the python path\n",
    "eml_path = '..'\n",
    "if not eml_path in sys.path:\n",
    "    sys.path.insert(1, eml_path)\n",
    "    \n",
    "# Load the data\n",
    "data_fname = os.path.join('shared', 'za_processed.h5')\n",
    "with pd.HDFStore(data_fname) as store:\n",
    "    data = store['data']\n",
    "    means_in = store['means_in']\n",
    "    stds_in = store['stds_in']\n",
    "    sim_in = store['sim_in']\n",
    "    sim_out = store['sim_out']\n",
    "    in_defaults = store['in_defaults']\n",
    "    pop_size = store['meta']['pop_size']\n",
    "\n",
    "    \n",
    "# Read the NN model\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# Load the model architecture\n",
    "net_prefixes = ['nn_reg_{}'.format(t) for t in sim_out]\n",
    "knet = {}\n",
    "def load_keras_nets(knet):\n",
    "    # Load scalar output NNs\n",
    "    for target, net_prefix in zip(sim_out, net_prefixes):\n",
    "        net_fname = os.path.join('shared', '{}.json'.format(net_prefix))\n",
    "        with open(net_fname) as fp:\n",
    "            knet[target] = model_from_json(fp.read())\n",
    "\n",
    "        # Load the model weights\n",
    "        wgt_fname = os.path.join('shared', '{}.h5'.format(net_prefix))\n",
    "        knet[target].load_weights(wgt_fname)\n",
    "\n",
    "    # Load vector output NN (this one is available in a single version)\n",
    "    net_fname = os.path.join('shared', 'nn_reg.json')\n",
    "    with open(net_fname) as fp:\n",
    "        knet['all'] = model_from_json(fp.read())\n",
    "\n",
    "    # Load the model weights\n",
    "    wgt_fname = os.path.join('shared', 'nn_reg.h5')\n",
    "    knet['all'].load_weights(wgt_fname)\n",
    "        \n",
    "load_keras_nets(knet)\n",
    "\n",
    "\n",
    "from eml.net import describe as ndescribe\n",
    "from eml.net.reader import keras_reader\n",
    "\n",
    "# Convert the Keras models in the EML format\n",
    "net = {}\n",
    "def convert_keras_net(knet, net):\n",
    "    # Convert scalar-output NNs\n",
    "    for target in sim_out:\n",
    "        net[target] = keras_reader.read_keras_sequential(knet[target])\n",
    "    \n",
    "    # Convert vector-output NN\n",
    "    net['all'] = keras_reader.read_keras_sequential(knet['all'])\n",
    "        \n",
    "convert_keras_net(knet, net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We manage the neuron bounds for the network encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TARGET: i_num\n",
      "[input] (0, 0):[-1.414, 1.414] (0, 1):[-1.224, 1.224] (0, 2):[-1.224, 1.224] (0, 3):[-1.521, 1.183] (0, 4):[-1.224, 1.224] (0, 5):[-1.224, 1.224]\n",
      "[dense,relu] (1, 0):[-2.426, 2.489]/[0.000, 2.489] (1, 1):[-2.487, 2.557]/[0.000, 2.557] (1, 2):[-2.746, 2.549]/[0.000, 2.549] (1, 3):[-2.135, 2.461]/[0.000, 2.461] (1, 4):[-1.446, 1.561]/[0.000, 1.561] (1, 5):[-1.665, 1.961]/[0.000, 1.961] (1, 6):[-1.788, 1.418]/[0.000, 1.418] (1, 7):[-2.509, 2.717]/[0.000, 2.717] (1, 8):[-1.169, 0.916]/[0.000, 0.916] (1, 9):[-1.503, 1.500]/[0.000, 1.500] (1, 10):[-0.735, 1.008]/[0.000, 1.008] (1, 11):[-1.496, 1.314]/[0.000, 1.314] (1, 12):[-1.665, 2.212]/[0.000, 2.212] (1, 13):[-3.177, 3.183]/[0.000, 3.183] (1, 14):[-1.652, 1.639]/[0.000, 1.639] (1, 15):[-2.641, 2.221]/[0.000, 2.221]\n",
      "[dense,relu] (2, 0):[-0.749, 1.575]/[0.000, 1.575] (2, 1):[-0.677, 1.593]/[0.000, 1.593] (2, 2):[-1.379, 0.918]/[0.000, 0.918] (2, 3):[-1.775, 0.708]/[0.000, 0.708] (2, 4):[-0.923, 1.530]/[0.000, 1.530] (2, 5):[-0.363, 1.504]/[0.000, 1.504] (2, 6):[-1.444, 1.422]/[0.000, 1.422] (2, 7):[-0.904, 0.606]/[0.000, 0.606] (2, 8):[-1.017, 1.130]/[0.000, 1.130] (2, 9):[-0.676, 1.043]/[0.000, 1.043] (2, 10):[-0.445, 1.697]/[0.000, 1.697] (2, 11):[-1.070, 1.205]/[0.000, 1.205] (2, 12):[-0.728, 1.093]/[0.000, 1.093] (2, 13):[-0.326, 1.805]/[0.000, 1.805] (2, 14):[-0.785, 1.239]/[0.000, 1.239] (2, 15):[-1.816, 0.371]/[0.000, 0.371]\n",
      "[dense,relu] (3, 0):[-1.225, 0.702]/[0.000, 0.702] (3, 1):[-1.034, 0.590]/[0.000, 0.590] (3, 2):[-2.054, 0.335]/[0.000, 0.335] (3, 3):[-0.264, 1.724]/[0.000, 1.724] (3, 4):[-0.741, 0.769]/[0.000, 0.769] (3, 5):[-1.491, 0.888]/[0.000, 0.888] (3, 6):[-0.495, 0.600]/[0.000, 0.600] (3, 7):[-0.275, 1.938]/[0.000, 1.938]\n",
      "[dense,linear] (4, 0):[-0.035, 0.986]/[-0.035, 0.986]\n",
      "\n",
      "=== TARGET: survivors\n",
      "[input] (0, 0):[-1.414, 1.414] (0, 1):[-1.224, 1.224] (0, 2):[-1.224, 1.224] (0, 3):[-1.521, 1.183] (0, 4):[-1.224, 1.224] (0, 5):[-1.224, 1.224]\n",
      "[dense,relu] (1, 0):[-1.372, 1.513]/[0.000, 1.513] (1, 1):[-1.693, 1.753]/[0.000, 1.753] (1, 2):[-1.918, 2.258]/[0.000, 2.258] (1, 3):[-2.028, 2.081]/[0.000, 2.081] (1, 4):[-1.770, 2.083]/[0.000, 2.083] (1, 5):[-2.080, 1.879]/[0.000, 1.879] (1, 6):[-1.650, 1.676]/[0.000, 1.676] (1, 7):[-1.995, 2.082]/[0.000, 2.082] (1, 8):[-1.880, 1.926]/[0.000, 1.926] (1, 9):[-1.606, 1.539]/[0.000, 1.539] (1, 10):[-1.852, 1.881]/[0.000, 1.881] (1, 11):[-1.881, 1.893]/[0.000, 1.893] (1, 12):[-1.463, 1.989]/[0.000, 1.989] (1, 13):[-1.289, 1.279]/[0.000, 1.279] (1, 14):[-2.417, 2.687]/[0.000, 2.687] (1, 15):[-1.263, 1.504]/[0.000, 1.504]\n",
      "[dense,relu] (2, 0):[-1.025, 1.493]/[0.000, 1.493] (2, 1):[-1.073, 1.612]/[0.000, 1.612] (2, 2):[-0.866, 2.133]/[0.000, 2.133] (2, 3):[-0.396, 1.836]/[0.000, 1.836] (2, 4):[-0.562, 1.137]/[0.000, 1.137] (2, 5):[-2.877, 1.285]/[0.000, 1.285] (2, 6):[-1.354, 2.135]/[0.000, 2.135] (2, 7):[-0.590, 1.473]/[0.000, 1.473] (2, 8):[-2.017, 0.533]/[0.000, 0.533] (2, 9):[-1.877, 1.136]/[0.000, 1.136] (2, 10):[-1.419, 1.643]/[0.000, 1.643] (2, 11):[-1.572, 0.918]/[0.000, 0.918] (2, 12):[-0.557, 1.473]/[0.000, 1.473] (2, 13):[-1.962, 0.291]/[0.000, 0.291] (2, 14):[-2.122, 0.909]/[0.000, 0.909] (2, 15):[-1.739, 1.086]/[0.000, 1.086]\n",
      "[dense,relu] (3, 0):[-0.669, 1.016]/[0.000, 1.016] (3, 1):[-1.185, 0.000]/[0.000, 0.000] (3, 2):[-0.758, 1.193]/[0.000, 1.193] (3, 3):[-0.469, 1.306]/[0.000, 1.306] (3, 4):[-0.293, 2.270]/[0.000, 2.270] (3, 5):[-0.432, 1.496]/[0.000, 1.496] (3, 6):[-0.885, 0.134]/[0.000, 0.134] (3, 7):[-0.412, 0.856]/[0.000, 0.856]\n",
      "[dense,linear] (4, 0):[-0.056, 1.140]/[-0.056, 1.140]\n",
      "\n",
      "=== TARGET: all\n",
      "[input] (0, 0):[-1.414, 1.414] (0, 1):[-1.224, 1.224] (0, 2):[-1.224, 1.224] (0, 3):[-1.521, 1.183] (0, 4):[-1.224, 1.224] (0, 5):[-1.224, 1.224]\n",
      "[dense,relu] (1, 0):[-2.205, 1.981]/[0.000, 1.981] (1, 1):[-2.401, 2.688]/[0.000, 2.688] (1, 2):[-2.803, 2.619]/[0.000, 2.619] (1, 3):[-1.396, 1.232]/[0.000, 1.232] (1, 4):[-1.581, 1.457]/[0.000, 1.457] (1, 5):[-1.556, 1.785]/[0.000, 1.785] (1, 6):[-2.131, 1.612]/[0.000, 1.612] (1, 7):[-2.103, 2.203]/[0.000, 2.203] (1, 8):[-1.307, 1.556]/[0.000, 1.556] (1, 9):[-1.383, 1.375]/[0.000, 1.375] (1, 10):[-1.068, 0.827]/[0.000, 0.827] (1, 11):[-1.494, 1.636]/[0.000, 1.636] (1, 12):[-1.641, 2.210]/[0.000, 2.210] (1, 13):[-3.512, 3.321]/[0.000, 3.321] (1, 14):[-1.587, 1.916]/[0.000, 1.916] (1, 15):[-2.522, 2.976]/[0.000, 2.976]\n",
      "[dense,relu] (2, 0):[-0.615, 1.990]/[0.000, 1.990] (2, 1):[-0.636, 2.052]/[0.000, 2.052] (2, 2):[-0.368, 1.597]/[0.000, 1.597] (2, 3):[-2.282, 0.489]/[0.000, 0.489] (2, 4):[-1.845, 1.004]/[0.000, 1.004] (2, 5):[-0.680, 0.966]/[0.000, 0.966] (2, 6):[-1.969, 0.691]/[0.000, 0.691] (2, 7):[-1.376, 0.484]/[0.000, 0.484] (2, 8):[-2.140, 0.665]/[0.000, 0.665] (2, 9):[-2.149, 0.560]/[0.000, 0.560] (2, 10):[-0.870, 2.280]/[0.000, 2.280] (2, 11):[-0.420, 1.356]/[0.000, 1.356] (2, 12):[-1.528, 1.337]/[0.000, 1.337] (2, 13):[-1.368, 1.149]/[0.000, 1.149] (2, 14):[-0.571, 0.607]/[0.000, 0.607] (2, 15):[-0.774, 1.713]/[0.000, 1.713]\n",
      "[dense,relu] (3, 0):[-1.224, 0.949]/[0.000, 0.949] (3, 1):[-0.188, 0.851]/[0.000, 0.851] (3, 2):[-1.161, 0.332]/[0.000, 0.332] (3, 3):[-1.121, 1.569]/[0.000, 1.569] (3, 4):[-0.727, 0.872]/[0.000, 0.872] (3, 5):[-0.173, 1.040]/[0.000, 1.040] (3, 6):[-0.235, 1.596]/[0.000, 1.596] (3, 7):[-0.255, 0.906]/[0.000, 0.906]\n",
      "[dense,linear] (4, 0):[-0.112, 0.974]/[-0.112, 0.974] (4, 1):[-0.077, 1.157]/[-0.077, 1.157]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtain basic input bounds from out dataset\n",
    "\n",
    "# Compute minima and maxima\n",
    "X_min, X_max = data[sim_in].min(), data[sim_in].max()\n",
    "# Standardize\n",
    "X_min = (X_min - means_in) / stds_in\n",
    "X_max = (X_max - means_in) / stds_in\n",
    "\n",
    "\n",
    "# Compute basic bounds\n",
    "from eml.net import process as nprocess\n",
    "\n",
    "def net_basic_bounds(net):\n",
    "    for target in list(sim_out) + ['all']:\n",
    "        # Reset existing bounds (just to ensure idempotence)\n",
    "        net[target].reset_bounds()\n",
    "\n",
    "        # Enforce basic input bounds\n",
    "        in_layer = net[target].layer(0)\n",
    "        for neuron, lb, ub in zip(in_layer.neurons(), X_min, X_max):\n",
    "            neuron.update_lb(lb)\n",
    "            neuron.update_ub(ub)\n",
    "\n",
    "        # Compute bounds for the hidden neurons via Interval Based Reasoning\n",
    "        nprocess.ibr_bounds(net[target])\n",
    "\n",
    "net_basic_bounds(net)\n",
    "\n",
    "#\n",
    "# Preprocessing: bound tightening\n",
    "#\n",
    "from eml.backend import cplex_backend\n",
    "\n",
    "# Build a backend object\n",
    "bkd = cplex_backend.CplexBackend()\n",
    "\n",
    "# Run forward bound tightening\n",
    "timelimit = 10\n",
    "def net_bound_tightening(net, timelimit):\n",
    "    for target in list(sim_out) + ['all']:\n",
    "        nprocess.fwd_bound_tighthening(bkd, net=net[target],\n",
    "                                      timelimit=timelimit)\n",
    "        # Display the bounds\n",
    "        print('=== TARGET: {}'.format(target))\n",
    "        print(net[target])\n",
    "        print()\n",
    "\n",
    "net_bound_tightening(net, timelimit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we model and solve the overall problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Starting the solution process\n",
      "=== SOLUTION DATA\n",
      "Solution time: 2.32 (sec)\n",
      "Solver status: integer optimal solution\n",
      "Survivors: 460.21208460748795\n",
      "Zombies: 19.834030954740207\n",
      "Cost: 69.0\n",
      "Chosen measures:\n",
      "* training_firearms\n",
      "* training_survival\n",
      "* training_stealth\n",
      "* training_medical\n",
      "* training_floormap\n",
      "* equipment_shotguns\n",
      "* equipment_rifles\n",
      "* equipment_bodyarmor\n",
      "* equipment_helmet\n",
      "* equipment_supplies\n",
      "* equipment_medical\n",
      "* equipment_distraction\n",
      "* building_sealed_doors\n",
      "* building_towers\n",
      "* building_medrooms\n",
      "* building_bunkers\n",
      "* policy_reduce_contact\n",
      "* policy_run\n",
      "* policy_hide\n",
      "Applicable bonuses:\n",
      "* training_firearms + equipment_shotguns\n",
      "* training_firearms + equipment_rifles\n",
      "* training_stealth + policy_hide\n",
      "Evaluation string: c(0.002, 0.330, 1.000, 0.000, 0.000, 0.170)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Load problem data\n",
    "#\n",
    "\n",
    "import json\n",
    "\n",
    "# Load the data about available measures\n",
    "measure_fname = os.path.join('data', 'measures.json')\n",
    "with open(measure_fname) as fp:\n",
    "    mdata = json.load(fp)\n",
    "\n",
    "# Separate the measure effect data from the combinations\n",
    "effects = mdata['effects']\n",
    "combinations = mdata['combinations']\n",
    "\n",
    "#\n",
    "# Build and solve a CPLEX model\n",
    "#\n",
    "\n",
    "from eml.backend import cplex_backend\n",
    "import docplex.mp.model as cpx\n",
    "from eml.net import embed as nembed\n",
    "from eml import util\n",
    "\n",
    "# Build a backend object\n",
    "bkd = cplex_backend.CplexBackend()\n",
    "# Build a docplex model\n",
    "mdl = cpx.Model()\n",
    "X_vars = []\n",
    "Y_vars = []\n",
    "Y_nat = []\n",
    "X_nat = []\n",
    "M_vars = []\n",
    "C_vars = []\n",
    "M_map = {}\n",
    "cost_var = mdl.continuous_var(name='cost')\n",
    "\n",
    "# Model construction functions\n",
    "def build_inout_vars(bkd, mdl, X_vars, Y_vars):\n",
    "    # Build one variable for each network input\n",
    "    for in_name, lb, ub in zip(sim_in, X_min, X_max):\n",
    "        X_vars.append(mdl.continuous_var(lb=lb, ub=ub, name=in_name))\n",
    "\n",
    "    # Build one variable for each network output\n",
    "    for out_name in sim_out:\n",
    "        # NOTE use slightly larger bounds (to account for approximation errors)\n",
    "        Y_vars.append(mdl.continuous_var(lb=-1, ub=2, name=out_name))\n",
    "\n",
    "\n",
    "def build_nat_out(bkd, mdl, Y_nat):\n",
    "    for i, out_name in enumerate(sim_out):\n",
    "        # Build the natural scale variable\n",
    "        lb = Y_vars[i].lb * pop_size\n",
    "        ub = Y_vars[i].ub * pop_size\n",
    "        ynat = mdl.continuous_var(lb=lb, ub=ub, name=out_name+'_nat')\n",
    "        Y_nat.append(ynat)\n",
    "\n",
    "        # Add the standardization constraints\n",
    "        mdl.add_constraint(Y_nat[i] == Y_vars[i] * pop_size)       \n",
    "\n",
    "\n",
    "def build_nat_in(bkd, mdl, X_nat):\n",
    "    for i, (in_name, lb, ub) in enumerate(zip(sim_in, X_min, X_max)):\n",
    "        # Build the natural scale variable\n",
    "        mean, std = means_in[in_name], stds_in[in_name]\n",
    "        lb_nat = lb * std + mean\n",
    "        ub_nat = ub * std + mean\n",
    "        span = ub_nat - lb_nat\n",
    "        xnat = mdl.continuous_var(lb=lb_nat-span, ub=ub_nat+span,\n",
    "                                  name=in_name+'_nat')\n",
    "        X_nat.append(xnat)\n",
    "\n",
    "        # Add the capping & standardization constraints\n",
    "        nat_nodes = [lb_nat-span, lb_nat, ub_nat, ub_nat+span]\n",
    "        std_nodes = [lb, lb, ub, ub]\n",
    "        util.encode_pwl(bkd, mdl, xvars=[X_nat[i], X_vars[i]],\n",
    "                        nodes=[nat_nodes, std_nodes],\n",
    "                       name=in_name)\n",
    "\n",
    "        \n",
    "def build_measure_vars(bkd, mdl, M_vars, C_vars, M_map):\n",
    "    # Build one binary variable per measure\n",
    "    for i, effect in enumerate(effects):\n",
    "        mvar = mdl.binary_var(name=effect['name'])\n",
    "        M_vars.append(mvar)\n",
    "        M_map[effect['name']] = i\n",
    "\n",
    "    # Build one binary variable per combination\n",
    "    for i, combo in enumerate(combinations):\n",
    "        cvar = mdl.binary_var(name='-'.join(combo['deps']))\n",
    "        C_vars.append(cvar)        \n",
    "\n",
    "\n",
    "def build_dependencies(bkd, mdl):\n",
    "    for i, combo in enumerate(combinations):\n",
    "        ndeps = len(combo['deps'])\n",
    "        mvars = [M_vars[M_map[name]] for name in combo['deps']]\n",
    "        mdl.add_constraint(ndeps * C_vars[i] <= sum(mvars))\n",
    "\n",
    "\n",
    "def build_measure_effect_csts(bkd, mdl):\n",
    "    for i, in_name in enumerate(sim_in):\n",
    "        # Effects to input\n",
    "        coefs, evars = [], []\n",
    "        for j, effect in enumerate(effects):\n",
    "            if in_name in effect:\n",
    "                coefs.append(effect[in_name])\n",
    "                evars.append(M_vars[j])\n",
    "        # Combinations to input\n",
    "        for j, combo in enumerate(combinations):\n",
    "            if in_name in combo:\n",
    "                coefs.append(combo[in_name])\n",
    "                evars.append(C_vars[j])\n",
    "        # Build the connection constraint\n",
    "        mdl.add_constraint(X_nat[i] == in_defaults[i] + mdl.scal_prod(evars, coefs))\n",
    "\n",
    "\n",
    "def build_cost_structure(bkd, mdl, cost_var):\n",
    "    # Measures to cost\n",
    "    coefs, evars = [], []\n",
    "    for i, effect in enumerate(effects):\n",
    "        coefs.append(effect['cost'])\n",
    "        evars.append(M_vars[i])\n",
    "    mdl.add_constraint(cost_var == mdl.scal_prod(evars, coefs))\n",
    "\n",
    "\n",
    "def build_network_encoding(bkd, mdl, mode='scalar'):\n",
    "    if mode == 'scalar':\n",
    "        for i, target in enumerate(sim_out):\n",
    "            nembed.encode(bkd, net[target], mdl, X_vars, Y_vars[i], target)\n",
    "    elif mode == 'vector':\n",
    "        nembed.encode(bkd, net['all'], mdl, X_vars, Y_vars, 'all')\n",
    "\n",
    "        \n",
    "# Build input and output variables\n",
    "build_inout_vars(bkd, mdl, X_vars, Y_vars)\n",
    "# Build a natural scale version of each output variable\n",
    "build_nat_out(bkd, mdl, Y_nat)\n",
    "# Build a natural scale version of each input variable\n",
    "build_nat_in(bkd, mdl, X_nat)\n",
    "# Build variables for the measures and their combinations\n",
    "build_measure_vars(bkd, mdl, M_vars, C_vars, M_map)\n",
    "# Build dependency constraints\n",
    "build_dependencies(bkd, mdl)\n",
    "# Connect effects and combinations to the natural-scale network inputs\n",
    "build_measure_effect_csts(bkd, mdl)\n",
    "# Build and constraint the cost variable\n",
    "build_cost_structure(bkd, mdl, cost_var)\n",
    "# Encode the network\n",
    "build_network_encoding(bkd, mdl, 'vector')\n",
    "\n",
    "# Budget\n",
    "mdl.add_constraint(cost_var <= 70)\n",
    "# Zombies\n",
    "mdl.add_constraint(Y_nat[0] <= 20)\n",
    "# Survivors\n",
    "mdl.set_objective('max', Y_nat[0])\n",
    "\n",
    "# Solve\n",
    "mdl.set_time_limit(30)\n",
    "print('=== Starting the solution process')\n",
    "sol = mdl.solve()\n",
    "\n",
    "if sol is None:\n",
    "    print('No solution found')\n",
    "else:\n",
    "    print('=== SOLUTION DATA')\n",
    "    print('Solution time: {:.2f} (sec)'.format(mdl.solve_details.time))\n",
    "    print('Solver status: {}'.format(sol.solve_details.status))\n",
    "    print('Survivors: {}'.format(sol[Y_nat[1]]))\n",
    "    print('Zombies: {}'.format(sol[Y_nat[0]]))\n",
    "    print('Cost: {}'.format(sol[cost_var]))\n",
    "    print('Chosen measures:')\n",
    "    for x, effect in zip(M_vars, effects):\n",
    "        if sol[x] > 0:\n",
    "            print('* {}'.format(effect['name']))\n",
    "    print('Applicable bonuses:')\n",
    "    for x, combo in zip(C_vars, combinations):\n",
    "        if sol[x] > 0:\n",
    "            print('* {}'.format(' + '.join(combo['deps'])))\n",
    "    cstring = 'c({})'.format(', '.join('{:.3f}'.format(max(0, sol[x])) for x in X_nat))\n",
    "    print('Evaluation string: {}'.format(cstring))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our old solution is no longer viable: we need to increase the budget if we want to keep things under control.\n",
    "\n",
    "We can now evaluate this final solution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
