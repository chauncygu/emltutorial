{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Final Round\n",
    "\n",
    "We can finally solve again the problem, with the new networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import importlib\n",
    "\n",
    "# Dynamically add the Empirical Model Learning folder to the python path\n",
    "eml_path = '..'\n",
    "if not eml_path in sys.path:\n",
    "    sys.path.insert(1, eml_path)\n",
    "    \n",
    "# Load the data\n",
    "data_fname = os.path.join('shared', 'za_processed.h5')\n",
    "with pd.HDFStore(data_fname) as store:\n",
    "    data = store['data']\n",
    "    means_in = store['means_in']\n",
    "    stds_in = store['stds_in']\n",
    "    sim_in = store['sim_in']\n",
    "    sim_out = store['sim_out']\n",
    "    in_defaults = store['in_defaults']\n",
    "    pop_size = store['meta']['pop_size']\n",
    "\n",
    "    \n",
    "# Read the NN model\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# Load the model architecture\n",
    "net_prefixes = ['nn_reg_{}'.format(t) for t in sim_out]\n",
    "knet = {}\n",
    "def load_keras_nets(knet):\n",
    "    # Load scalar output NNs\n",
    "    for target, net_prefix in zip(sim_out, net_prefixes):\n",
    "        net_fname = os.path.join('shared', '{}.json'.format(net_prefix))\n",
    "        with open(net_fname) as fp:\n",
    "            knet[target] = model_from_json(fp.read())\n",
    "\n",
    "        # Load the model weights\n",
    "        wgt_fname = os.path.join('shared', '{}.h5'.format(net_prefix))\n",
    "        knet[target].load_weights(wgt_fname)\n",
    "\n",
    "    # Load vector output NN (this one is available in a single version)\n",
    "    net_fname = os.path.join('shared', 'nn_reg.json')\n",
    "    with open(net_fname) as fp:\n",
    "        knet['all'] = model_from_json(fp.read())\n",
    "\n",
    "    # Load the model weights\n",
    "    wgt_fname = os.path.join('shared', 'nn_reg.h5')\n",
    "    knet['all'].load_weights(wgt_fname)\n",
    "        \n",
    "load_keras_nets(knet)\n",
    "\n",
    "\n",
    "from eml.net import describe as ndescribe\n",
    "from eml.net.reader import keras_reader\n",
    "\n",
    "# Convert the Keras models in the EML format\n",
    "net = {}\n",
    "def convert_keras_net(knet, net):\n",
    "    # Convert scalar-output NNs\n",
    "    for target in sim_out:\n",
    "        net[target] = keras_reader.read_keras_sequential(knet[target])\n",
    "    \n",
    "    # Convert vector-output NN\n",
    "    net['all'] = keras_reader.read_keras_sequential(knet['all'])\n",
    "        \n",
    "convert_keras_net(knet, net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We manage the neuron bounds for the network encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TARGET: i_num\n",
      "[input] (0, 0):[-1.414, 1.414] (0, 1):[-1.224, 1.224] (0, 2):[-1.224, 1.224] (0, 3):[-1.521, 1.183] (0, 4):[-1.224, 1.224] (0, 5):[-1.224, 1.224]\n",
      "[dense,relu] (1, 0):[-2.431, 2.497]/[0.000, 2.497] (1, 1):[-2.495, 2.561]/[0.000, 2.561] (1, 2):[-2.736, 2.538]/[0.000, 2.538] (1, 3):[-2.137, 2.470]/[0.000, 2.470] (1, 4):[-1.464, 1.562]/[0.000, 1.562] (1, 5):[-1.675, 1.972]/[0.000, 1.972] (1, 6):[-1.767, 1.396]/[0.000, 1.396] (1, 7):[-2.493, 2.706]/[0.000, 2.706] (1, 8):[-1.166, 0.910]/[0.000, 0.910] (1, 9):[-1.531, 1.521]/[0.000, 1.521] (1, 10):[-0.725, 1.002]/[0.000, 1.002] (1, 11):[-1.489, 1.305]/[0.000, 1.305] (1, 12):[-1.665, 2.212]/[0.000, 2.212] (1, 13):[-3.176, 3.173]/[0.000, 3.173] (1, 14):[-1.623, 1.611]/[0.000, 1.611] (1, 15):[-2.645, 2.220]/[0.000, 2.220]\n",
      "[dense,relu] (2, 0):[-0.727, 1.567]/[0.000, 1.567] (2, 1):[-0.678, 1.589]/[0.000, 1.589] (2, 2):[-1.392, 0.921]/[0.000, 0.921] (2, 3):[-1.772, 0.707]/[0.000, 0.707] (2, 4):[-0.968, 1.508]/[0.000, 1.508] (2, 5):[-0.362, 1.521]/[0.000, 1.521] (2, 6):[-1.427, 1.421]/[0.000, 1.421] (2, 7):[-0.902, 0.609]/[0.000, 0.609] (2, 8):[-1.019, 1.116]/[0.000, 1.116] (2, 9):[-0.688, 1.052]/[0.000, 1.052] (2, 10):[-0.451, 1.685]/[0.000, 1.685] (2, 11):[-1.066, 1.208]/[0.000, 1.208] (2, 12):[-0.728, 1.099]/[0.000, 1.099] (2, 13):[-0.338, 1.821]/[0.000, 1.821] (2, 14):[-0.758, 1.251]/[0.000, 1.251] (2, 15):[-1.824, 0.362]/[0.000, 0.362]\n",
      "[dense,relu] (3, 0):[-1.212, 0.687]/[0.000, 0.687] (3, 1):[-1.047, 0.591]/[0.000, 0.591] (3, 2):[-2.037, 0.336]/[0.000, 0.336] (3, 3):[-0.244, 1.693]/[0.000, 1.693] (3, 4):[-0.739, 0.777]/[0.000, 0.777] (3, 5):[-1.505, 0.881]/[0.000, 0.881] (3, 6):[-0.490, 0.584]/[0.000, 0.584] (3, 7):[-0.274, 1.937]/[0.000, 1.937]\n",
      "[dense,linear] (4, 0):[-0.035, 1.331]/[-0.035, 1.331]\n",
      "\n",
      "=== TARGET: survivors\n",
      "[input] (0, 0):[-1.414, 1.414] (0, 1):[-1.224, 1.224] (0, 2):[-1.224, 1.224] (0, 3):[-1.521, 1.183] (0, 4):[-1.224, 1.224] (0, 5):[-1.224, 1.224]\n",
      "[dense,relu] (1, 0):[-1.369, 1.504]/[0.000, 1.504] (1, 1):[-1.700, 1.764]/[0.000, 1.764] (1, 2):[-1.914, 2.256]/[0.000, 2.256] (1, 3):[-2.042, 2.103]/[0.000, 2.103] (1, 4):[-1.758, 2.071]/[0.000, 2.071] (1, 5):[-2.092, 1.892]/[0.000, 1.892] (1, 6):[-1.650, 1.678]/[0.000, 1.678] (1, 7):[-1.989, 2.072]/[0.000, 2.072] (1, 8):[-1.878, 1.924]/[0.000, 1.924] (1, 9):[-1.599, 1.532]/[0.000, 1.532] (1, 10):[-1.843, 1.879]/[0.000, 1.879] (1, 11):[-1.872, 1.881]/[0.000, 1.881] (1, 12):[-1.464, 1.986]/[0.000, 1.986] (1, 13):[-1.276, 1.270]/[0.000, 1.270] (1, 14):[-2.423, 2.693]/[0.000, 2.693] (1, 15):[-1.264, 1.505]/[0.000, 1.505]\n",
      "[dense,relu] (2, 0):[-1.034, 1.504]/[0.000, 1.504] (2, 1):[-1.057, 1.631]/[0.000, 1.631] (2, 2):[-0.866, 2.148]/[0.000, 2.148] (2, 3):[-0.397, 1.848]/[0.000, 1.848] (2, 4):[-0.571, 1.133]/[0.000, 1.133] (2, 5):[-2.855, 1.266]/[0.000, 1.266] (2, 6):[-1.343, 2.143]/[0.000, 2.143] (2, 7):[-0.599, 1.479]/[0.000, 1.479] (2, 8):[-2.020, 0.487]/[0.000, 0.487] (2, 9):[-1.924, 1.127]/[0.000, 1.127] (2, 10):[-1.423, 1.659]/[0.000, 1.659] (2, 11):[-1.580, 0.912]/[0.000, 0.912] (2, 12):[-0.533, 1.463]/[0.000, 1.463] (2, 13):[-2.036, 0.299]/[0.000, 0.299] (2, 14):[-2.138, 0.906]/[0.000, 0.906] (2, 15):[-1.727, 1.148]/[0.000, 1.148]\n",
      "[dense,relu] (3, 0):[-0.671, 1.016]/[0.000, 1.016] (3, 1):[-1.218, 0.000]/[0.000, 0.000] (3, 2):[-0.715, 1.211]/[0.000, 1.211] (3, 3):[-0.465, 1.315]/[0.000, 1.315] (3, 4):[-0.309, 2.278]/[0.000, 2.278] (3, 5):[-0.418, 1.489]/[0.000, 1.489] (3, 6):[-0.901, 0.134]/[0.000, 0.134] (3, 7):[-0.407, 0.851]/[0.000, 0.851]\n",
      "[dense,linear] (4, 0):[-0.059, 1.137]/[-0.059, 1.137]\n",
      "\n",
      "=== TARGET: all\n",
      "[input] (0, 0):[-1.414, 1.414] (0, 1):[-1.224, 1.224] (0, 2):[-1.224, 1.224] (0, 3):[-1.521, 1.183] (0, 4):[-1.224, 1.224] (0, 5):[-1.224, 1.224]\n",
      "[dense,relu] (1, 0):[-2.205, 1.992]/[0.000, 1.992] (1, 1):[-2.407, 2.689]/[0.000, 2.689] (1, 2):[-2.809, 2.593]/[0.000, 2.593] (1, 3):[-1.419, 1.242]/[0.000, 1.242] (1, 4):[-1.576, 1.450]/[0.000, 1.450] (1, 5):[-1.567, 1.791]/[0.000, 1.791] (1, 6):[-2.141, 1.623]/[0.000, 1.623] (1, 7):[-2.108, 2.223]/[0.000, 2.223] (1, 8):[-1.301, 1.551]/[0.000, 1.551] (1, 9):[-1.376, 1.373]/[0.000, 1.373] (1, 10):[-1.073, 0.829]/[0.000, 0.829] (1, 11):[-1.498, 1.642]/[0.000, 1.642] (1, 12):[-1.637, 2.196]/[0.000, 2.196] (1, 13):[-3.530, 3.338]/[0.000, 3.338] (1, 14):[-1.594, 1.922]/[0.000, 1.922] (1, 15):[-2.515, 2.978]/[0.000, 2.978]\n",
      "[dense,relu] (2, 0):[-0.627, 1.990]/[0.000, 1.990] (2, 1):[-0.654, 2.045]/[0.000, 2.045] (2, 2):[-0.347, 1.582]/[0.000, 1.582] (2, 3):[-2.303, 0.483]/[0.000, 0.483] (2, 4):[-1.820, 0.994]/[0.000, 0.994] (2, 5):[-0.701, 0.961]/[0.000, 0.961] (2, 6):[-1.920, 0.646]/[0.000, 0.646] (2, 7):[-1.390, 0.480]/[0.000, 0.480] (2, 8):[-2.144, 0.679]/[0.000, 0.679] (2, 9):[-2.147, 0.544]/[0.000, 0.544] (2, 10):[-0.873, 2.301]/[0.000, 2.301] (2, 11):[-0.386, 1.380]/[0.000, 1.380] (2, 12):[-1.533, 1.294]/[0.000, 1.294] (2, 13):[-1.266, 1.132]/[0.000, 1.132] (2, 14):[-0.589, 0.637]/[0.000, 0.637] (2, 15):[-0.818, 1.573]/[0.000, 1.573]\n",
      "[dense,relu] (3, 0):[-1.436, 0.859]/[0.000, 0.859] (3, 1):[-0.148, 0.836]/[0.000, 0.836] (3, 2):[-1.151, 0.365]/[0.000, 0.365] (3, 3):[-1.079, 1.546]/[0.000, 1.546] (3, 4):[-0.739, 0.883]/[0.000, 0.883] (3, 5):[-0.154, 1.004]/[0.000, 1.004] (3, 6):[-0.250, 1.649]/[0.000, 1.649] (3, 7):[-0.276, 0.935]/[0.000, 0.935]\n",
      "[dense,linear] (4, 0):[-0.125, 0.976]/[-0.125, 0.976] (4, 1):[-0.077, 1.166]/[-0.077, 1.166]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtain basic input bounds from out dataset\n",
    "\n",
    "# Compute minima and maxima\n",
    "X_min, X_max = data[sim_in].min(), data[sim_in].max()\n",
    "# Standardize\n",
    "X_min = (X_min - means_in) / stds_in\n",
    "X_max = (X_max - means_in) / stds_in\n",
    "\n",
    "\n",
    "# Compute basic bounds\n",
    "from eml.net import process as nprocess\n",
    "\n",
    "def net_basic_bounds(net):\n",
    "    for target in list(sim_out) + ['all']:\n",
    "        # Reset existing bounds (just to ensure idempotence)\n",
    "        net[target].reset_bounds()\n",
    "\n",
    "        # Enforce basic input bounds\n",
    "        in_layer = net[target].layer(0)\n",
    "        for neuron, lb, ub in zip(in_layer.neurons(), X_min, X_max):\n",
    "            neuron.update_lb(lb)\n",
    "            neuron.update_ub(ub)\n",
    "\n",
    "        # Compute bounds for the hidden neurons via Interval Based Reasoning\n",
    "        nprocess.ibr_bounds(net[target])\n",
    "\n",
    "net_basic_bounds(net)\n",
    "\n",
    "#\n",
    "# Preprocessing: bound tightening\n",
    "#\n",
    "from eml.backend import cplex_backend\n",
    "\n",
    "# Build a backend object\n",
    "bkd = cplex_backend.CplexBackend()\n",
    "\n",
    "# Run forward bound tightening\n",
    "timelimit = 10\n",
    "def net_bound_tightening(net, timelimit):\n",
    "    for target in list(sim_out) + ['all']:\n",
    "        nprocess.fwd_bound_tighthening(bkd, net=net[target],\n",
    "                                      timelimit=timelimit)\n",
    "        # Display the bounds\n",
    "        print('=== TARGET: {}'.format(target))\n",
    "        print(net[target])\n",
    "        print()\n",
    "\n",
    "net_bound_tightening(net, timelimit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we model and solve the overall problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Starting the solution process\n",
      "No solution found\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Load problem data\n",
    "#\n",
    "\n",
    "import json\n",
    "\n",
    "# Load the data about available measures\n",
    "measure_fname = os.path.join('data', 'measures.json')\n",
    "with open(measure_fname) as fp:\n",
    "    mdata = json.load(fp)\n",
    "\n",
    "# Separate the measure effect data from the combinations\n",
    "effects = mdata['effects']\n",
    "combinations = mdata['combinations']\n",
    "\n",
    "#\n",
    "# Build and solve a CPLEX model\n",
    "#\n",
    "\n",
    "from eml.backend import cplex_backend\n",
    "import docplex.mp.model as cpx\n",
    "from eml.net import embed as nembed\n",
    "from eml import util\n",
    "\n",
    "# Build a backend object\n",
    "bkd = cplex_backend.CplexBackend()\n",
    "# Build a docplex model\n",
    "mdl = cpx.Model()\n",
    "X_vars = []\n",
    "Y_vars = []\n",
    "Y_nat = []\n",
    "X_nat = []\n",
    "M_vars = []\n",
    "C_vars = []\n",
    "M_map = {}\n",
    "cost_var = mdl.continuous_var(name='cost')\n",
    "\n",
    "# Model construction functions\n",
    "def build_inout_vars(bkd, mdl, X_vars, Y_vars):\n",
    "    # Build one variable for each network input\n",
    "    for in_name, lb, ub in zip(sim_in, X_min, X_max):\n",
    "        X_vars.append(mdl.continuous_var(lb=lb, ub=ub, name=in_name))\n",
    "\n",
    "    # Build one variable for each network output\n",
    "    for out_name in sim_out:\n",
    "        # NOTE use slightly larger bounds (to account for approximation errors)\n",
    "        Y_vars.append(mdl.continuous_var(lb=-1, ub=2, name=out_name))\n",
    "\n",
    "\n",
    "def build_nat_out(bkd, mdl, Y_nat):\n",
    "    for i, out_name in enumerate(sim_out):\n",
    "        # Build the natural scale variable\n",
    "        lb = Y_vars[i].lb * pop_size\n",
    "        ub = Y_vars[i].ub * pop_size\n",
    "        ynat = mdl.continuous_var(lb=lb, ub=ub, name=out_name+'_nat')\n",
    "        Y_nat.append(ynat)\n",
    "\n",
    "        # Add the standardization constraints\n",
    "        mdl.add_constraint(Y_nat[i] == Y_vars[i] * pop_size)       \n",
    "\n",
    "\n",
    "def build_nat_in(bkd, mdl, X_nat):\n",
    "    for i, (in_name, lb, ub) in enumerate(zip(sim_in, X_min, X_max)):\n",
    "        # Build the natural scale variable\n",
    "        mean, std = means_in[in_name], stds_in[in_name]\n",
    "        lb_nat = lb * std + mean\n",
    "        ub_nat = ub * std + mean\n",
    "        span = ub_nat - lb_nat\n",
    "        xnat = mdl.continuous_var(lb=lb_nat-span, ub=ub_nat+span,\n",
    "                                  name=in_name+'_nat')\n",
    "        X_nat.append(xnat)\n",
    "\n",
    "        # Add the capping & standardization constraints\n",
    "        nat_nodes = [lb_nat-span, lb_nat, ub_nat, ub_nat+span]\n",
    "        std_nodes = [lb, lb, ub, ub]\n",
    "        util.encode_pwl(bkd, mdl, xvars=[X_nat[i], X_vars[i]],\n",
    "                        nodes=[nat_nodes, std_nodes],\n",
    "                       name=in_name)\n",
    "\n",
    "        \n",
    "def build_measure_vars(bkd, mdl, M_vars, C_vars, M_map):\n",
    "    # Build one binary variable per measure\n",
    "    for i, effect in enumerate(effects):\n",
    "        mvar = mdl.binary_var(name=effect['name'])\n",
    "        M_vars.append(mvar)\n",
    "        M_map[effect['name']] = i\n",
    "\n",
    "    # Build one binary variable per combination\n",
    "    for i, combo in enumerate(combinations):\n",
    "        cvar = mdl.binary_var(name='-'.join(combo['deps']))\n",
    "        C_vars.append(cvar)        \n",
    "\n",
    "\n",
    "def build_dependencies(bkd, mdl):\n",
    "    for i, combo in enumerate(combinations):\n",
    "        ndeps = len(combo['deps'])\n",
    "        mvars = [M_vars[M_map[name]] for name in combo['deps']]\n",
    "        mdl.add_constraint(ndeps * C_vars[i] <= sum(mvars))\n",
    "\n",
    "\n",
    "def build_measure_effect_csts(bkd, mdl):\n",
    "    for i, in_name in enumerate(sim_in):\n",
    "        # Effects to input\n",
    "        coefs, evars = [], []\n",
    "        for j, effect in enumerate(effects):\n",
    "            if in_name in effect:\n",
    "                coefs.append(effect[in_name])\n",
    "                evars.append(M_vars[j])\n",
    "        # Combinations to input\n",
    "        for j, combo in enumerate(combinations):\n",
    "            if in_name in combo:\n",
    "                coefs.append(combo[in_name])\n",
    "                evars.append(C_vars[j])\n",
    "        # Build the connection constraint\n",
    "        mdl.add_constraint(X_nat[i] == in_defaults[i] + mdl.scal_prod(evars, coefs))\n",
    "\n",
    "\n",
    "def build_cost_structure(bkd, mdl, cost_var):\n",
    "    # Measures to cost\n",
    "    coefs, evars = [], []\n",
    "    for i, effect in enumerate(effects):\n",
    "        coefs.append(effect['cost'])\n",
    "        evars.append(M_vars[i])\n",
    "    mdl.add_constraint(cost_var == mdl.scal_prod(evars, coefs))\n",
    "\n",
    "\n",
    "def build_network_encoding(bkd, mdl, mode='scalar'):\n",
    "    if mode == 'scalar':\n",
    "        for i, target in enumerate(sim_out):\n",
    "            nembed.encode(bkd, net[target], mdl, X_vars, Y_vars[i], target)\n",
    "    elif mode == 'vector':\n",
    "        nembed.encode(bkd, net['all'], mdl, X_vars, Y_vars, 'all')\n",
    "\n",
    "        \n",
    "# Build input and output variables\n",
    "build_inout_vars(bkd, mdl, X_vars, Y_vars)\n",
    "# Build a natural scale version of each output variable\n",
    "build_nat_out(bkd, mdl, Y_nat)\n",
    "# Build a natural scale version of each input variable\n",
    "build_nat_in(bkd, mdl, X_nat)\n",
    "# Build variables for the measures and their combinations\n",
    "build_measure_vars(bkd, mdl, M_vars, C_vars, M_map)\n",
    "# Build dependency constraints\n",
    "build_dependencies(bkd, mdl)\n",
    "# Connect effects and combinations to the natural-scale network inputs\n",
    "build_measure_effect_csts(bkd, mdl)\n",
    "# Build and constraint the cost variable\n",
    "build_cost_structure(bkd, mdl, cost_var)\n",
    "# Encode the network\n",
    "build_network_encoding(bkd, mdl, 'vector')\n",
    "\n",
    "# Budget\n",
    "mdl.add_constraint(cost_var <= 70)\n",
    "# Zombies\n",
    "mdl.add_constraint(Y_nat[0] <= 20)\n",
    "# Survivors\n",
    "mdl.set_objective('max', Y_nat[0])\n",
    "\n",
    "# Solve\n",
    "mdl.set_time_limit(30)\n",
    "print('=== Starting the solution process')\n",
    "sol = mdl.solve()\n",
    "\n",
    "if sol is None:\n",
    "    print('No solution found')\n",
    "else:\n",
    "    print('=== SOLUTION DATA')\n",
    "    print('Solution time: {:.2f} (sec)'.format(mdl.solve_details.time))\n",
    "    print('Solver status: {}'.format(sol.solve_details.status))\n",
    "    print('Survivors: {}'.format(sol[Y_nat[1]]))\n",
    "    print('Zombies: {}'.format(sol[Y_nat[0]]))\n",
    "    print('Cost: {}'.format(sol[cost_var]))\n",
    "    print('Chosen measures:')\n",
    "    for x, effect in zip(M_vars, effects):\n",
    "        if sol[x] > 0:\n",
    "            print('* {}'.format(effect['name']))\n",
    "    print('Applicable bonuses:')\n",
    "    for x, combo in zip(C_vars, combinations):\n",
    "        if sol[x] > 0:\n",
    "            print('* {}'.format(' + '.join(combo['deps'])))\n",
    "    cstring = 'c({})'.format(', '.join('{:.3f}'.format(max(0, sol[x])) for x in X_nat))\n",
    "    print('Evaluation string: {}'.format(cstring))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our old solution is no longer viable: we need to increase the budget if we want to keep things under control.\n",
    "\n",
    "We can now evaluate this final solution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
