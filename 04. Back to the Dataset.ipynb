{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back to the Dataset\n",
    "\n",
    "So far, we have disergarded to important facts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) We are dealing with a stochastic process\n",
    "\n",
    "Let's have a look at the data from this perspective:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "# Load data\n",
    "data_fname = os.path.join('data', 'za_data.csv')\n",
    "data = pd.read_csv(data_fname)\n",
    "\n",
    "# Some meta-information\n",
    "sim_in = ['edge_ratio', 'inf_prob', 'act_rate', 'rec_rate', 'ds_rate', 'di_rate']\n",
    "sim_out = ['i_num', 'survivors']\n",
    "n_in = len(sim_in)\n",
    "n_out = len(sim_out)\n",
    "in_defaults = [0.004, 0.7, 3, 0, 0.05, 0.00]\n",
    "pop_size = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are our data distributions, if we just look at the examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a new column (number of survivors)\n",
    "data['survivors'] = data['s_num'] + data['r_num']\n",
    "\n",
    "# Plot a a few distribution\n",
    "nbins = 20\n",
    "plt.figure(figsize=(15, 9))\n",
    "# --- Susceptibles\n",
    "plt.subplot(411)\n",
    "plt.title('Number of survivors')\n",
    "plt.hist(data.survivors, bins=nbins, density=True)\n",
    "# --- Infected\n",
    "plt.subplot(412)\n",
    "plt.title('Number of zombies')\n",
    "plt.hist(data.i_num, bins=nbins, density=True)\n",
    "# --- Total\n",
    "plt.subplot(413)\n",
    "plt.title('Number of individuals')\n",
    "plt.hist(data.num, bins=nbins, density=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's the same information, after we have computed the min/max of simulations done with the same input parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum number of zombies per scenario\n",
    "gby = data.groupby(sim_in)\n",
    "nbins = 20\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "plt.title('Min number of zombies per input configuration')\n",
    "plt.hist(gby['i_num'].min(), bins=nbins, density=True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "plt.title('Maximum number of zombies per input configuration')\n",
    "plt.hist(gby['i_num'].max(), bins=nbins, density=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is considerable variability: in this situation, our network model has a hard time making an accurate prediction: when optimizing the weights for minimum MSE, there is large irreducible error.\n",
    "\n",
    "One way to deal with this situation is to pre-aggregate the data, for example by taking the mean over groups of runs with the same values for the input parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum number of zombies per scenario\n",
    "gby = data.groupby(sim_in)\n",
    "nbins = 20\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "plt.title('Mean number of zombies per input configuration')\n",
    "plt.hist(gby['i_num'].mean(), bins=nbins, density=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also repeat our analysis of the impact of each paramter from this perspective:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute averages by input value\n",
    "mdata = gby[['i_num', 'survivors']].mean().reset_index()\n",
    "mdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effect of the input parameters in the number of survivorss\n",
    "nrows = int(np.ceil(n_in / 3))\n",
    "plt.figure(figsize=(15, 5*nrows))\n",
    "for i, in_name in enumerate(sim_in):\n",
    "    plt.subplot(nrows, 3, i+1)\n",
    "    plt.scatter(mdata[in_name], mdata['survivors'], marker='+', label='survivors', color='C0', alpha=0.5)\n",
    "    plt.xlabel(in_name)\n",
    "    plt.ylabel('survivors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effect of the input parameters in the number of survivorss\n",
    "nrows = int(np.ceil(n_in / 3))\n",
    "plt.figure(figsize=(15, 5*nrows))\n",
    "for i, in_name in enumerate(sim_in):\n",
    "    plt.subplot(nrows, 3, i+1)\n",
    "    plt.scatter(mdata[in_name], mdata['i_num'], marker='+', label='survivors', color='C1', alpha=0.5)\n",
    "    plt.xlabel(in_name)\n",
    "    plt.ylabel('zombies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) We have split the dataset at random\n",
    "\n",
    "In ML tasks, it is common to obtain training, validation, and test data via random splitting. This is done because usually the dataset encodes some _desired_ bias on the probability distribution of the real data the we want to preserve.\n",
    "\n",
    "However, the ML task that we are addressing is _very different_.\n",
    "\n",
    "We will eventually embed our ML models into an optimization model, which will be explored by a solver looking for an optimal solution. In this setting, _it is very hard to know a priory which areas of the search space need to be better represented_.\n",
    "\n",
    "One way to deal with this issue is to resort to active learning: for examples, see [our survey on integrating ML and optimization at the modeling level](). So far, active learning in the context of EML has not been investigated: this is an open research direction!\n",
    "\n",
    "Another method to deal with the same issue consists in doing what we have in fact already done: using a factorial design for generating the dataset, so that all areas of the search space are decently represented in the dataset. \n",
    "\n",
    "If we take this approach, however, it makes sense to _respect the factorial design when splitting the dataset_.\n",
    "\n",
    "Note that this is not really hurting our results right now (random splitting still results in dataset with similar distributions), but will end up haunting us later, at problem solving time, like an angry ghost or a particularly greasy dinner ;-) \n",
    "\n",
    "Let's do this split & aggregate thing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate + split into training, validation, and test data\n",
    "data_tr = []\n",
    "data_vl = []\n",
    "data_ts = []\n",
    "for lbl, gdata in data.groupby(sim_in):\n",
    "    lnum = len(gdata)\n",
    "    sep1 = int(lnum * 2/3)\n",
    "    sep2 = int(lnum * 5/6)\n",
    "    gdata_tr = gdata.iloc[:sep1]\n",
    "    gdata_vl = gdata.iloc[sep1:sep2]\n",
    "    gdata_ts = gdata.iloc[sep2:]\n",
    "    data_tr.append(lbl + (gdata_tr['i_num'].mean(),) + (gdata_tr['survivors'].mean(),))\n",
    "    data_vl.append(lbl + (gdata_vl['i_num'].mean(),) + (gdata_vl['survivors'].mean(),))\n",
    "    data_ts.append(lbl + (gdata_ts['i_num'].mean(),) + (gdata_ts['survivors'].mean(),))\n",
    "    \n",
    "data_tr = pd.DataFrame(data=data_tr, columns=sim_in + sim_out)\n",
    "data_vl = pd.DataFrame(data=data_vl, columns=sim_in + sim_out)\n",
    "data_ts = pd.DataFrame(data=data_ts, columns=sim_in + sim_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to standardize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize inputs\n",
    "means_in = data_tr[sim_in].mean(axis=0)\n",
    "stds_in = data_tr[sim_in].std(axis=0)\n",
    "data_tr[sim_in] = (data_tr[sim_in] - means_in) / stds_in\n",
    "data_vl[sim_in] = (data_vl[sim_in] - means_in) / stds_in\n",
    "data_ts[sim_in] = (data_ts[sim_in] - means_in) / stds_in\n",
    "\n",
    "# Standardize output\n",
    "data_tr[sim_out] /= pop_size\n",
    "data_vl[sim_out] /= pop_size\n",
    "data_ts[sim_out] /= pop_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to store the new datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store into an HDF5 archive\n",
    "hdf_fname = os.path.join('shared', 'za_processed.h5')\n",
    "with pd.HDFStore(hdf_fname, 'w') as store:\n",
    "    store['data'] = data\n",
    "    store['data_tr'] = data_tr\n",
    "    store['data_vl'] = data_vl\n",
    "    store['data_ts'] = data_ts\n",
    "    store['means_in'] = means_in\n",
    "    store['stds_in'] = stds_in\n",
    "    store['sim_in'] = pd.Series(sim_in)\n",
    "    store['sim_out'] = pd.Series(sim_out)\n",
    "    store['in_defaults'] = pd.Series(index=sim_in, data=in_defaults)\n",
    "    store['meta'] = pd.Series(index=['pop_size'], data=[pop_size])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
