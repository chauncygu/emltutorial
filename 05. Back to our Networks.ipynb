{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning a Neural Network\n",
    "\n",
    "We can now try to learn Neural Network models to predict the aggregated outputs.\n",
    "\n",
    "First, let's load the new datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data_fname = os.path.join('shared', 'za_processed.h5')\n",
    "with pd.HDFStore(data_fname) as store:\n",
    "    data_tr = store['data_tr']\n",
    "    data_vl = store['data_vl']\n",
    "    data_ts = store['data_ts']\n",
    "    means_in = store['means_in']\n",
    "    stds_in = store['stds_in']\n",
    "    sim_in = store['sim_in']\n",
    "    sim_out = store['sim_out']\n",
    "    in_defaults = store['in_defaults']\n",
    "    pop_size = store['meta']['pop_size']\n",
    "\n",
    "# Separate input and output\n",
    "X_tr = data_tr[sim_in]\n",
    "Y_tr = data_tr[sim_out]\n",
    "X_vl = data_vl[sim_in]\n",
    "Y_vl = data_vl[sim_out]\n",
    "X_ts = data_ts[sim_in]\n",
    "Y_ts = data_ts[sim_out]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalar Output\n",
    "\n",
    "Let's first see what happens with scalar outputs. Let's start directly from the deeper model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import backend as K\n",
    "import tensorflow\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Seed the RNGs\n",
    "np.random.seed(42)\n",
    "tensorflow.set_random_seed(42)\n",
    "\n",
    "# Custom R2 metric (courtesy of https://www.kaggle.com/c/mercedes-benz-greener-manufacturing/discussion/34019)\n",
    "def r2_score(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "# Input shape\n",
    "input_shape = (X_tr.shape[1],)\n",
    "\n",
    "# Handle outputs\n",
    "max_epochs = 50\n",
    "for target in sim_out:\n",
    "    y_tr = Y_tr[target].values\n",
    "    y_vl = Y_vl[target].values\n",
    "    y_ts = Y_ts[target].values\n",
    "\n",
    "    # Define a Neural Network model to predict the number of infected\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, activation='relu', input_shape=input_shape))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    # Compile\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='mse',\n",
    "                  metrics=[r2_score])\n",
    "\n",
    "    # Setup and perform training\n",
    "    weight_fname = os.path.join('shared', 'nn_reg_%s.h5' % target)\n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience=5),\n",
    "                 ModelCheckpoint(filepath=weight_fname, monitor='val_loss', save_best_only=True)]\n",
    "    model.fit(X_tr, y_tr, epochs=max_epochs, batch_size=32, callbacks=callbacks,\n",
    "              validation_data=(X_vl, y_vl), verbose=0)\n",
    "    \n",
    "    # Save the model architecture\n",
    "    arch_fname = os.path.join('shared', 'nn_reg_%s.json' % target)\n",
    "    with open(arch_fname, 'w') as fp:\n",
    "        fp.write(model.to_json())\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    print('=== Results for target \"{}\"'.format(target))\n",
    "    res_tr = model.evaluate(X_tr, y_tr, batch_size=len(X_tr))\n",
    "    print('Loss and R2 on the training set: {}, {}'.format(*res_tr))\n",
    "    res_vl = model.evaluate(X_vl, y_vl, batch_size=len(X_vl))\n",
    "    print('Loss and R2 on the validation set: {}, {}'.format(*res_vl) )\n",
    "    res_ts = model.evaluate(X_ts, y_ts, batch_size=len(X_ts))\n",
    "    print('Loss and R2 on the test set: {}, {}'.format(*res_ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Way better! There's still a little bit of overfitting, unfortunately.\n",
    "\n",
    "Training is faster, because the aggregation has effectively reduced by 20 times the number of examples (which is both good and bad)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Output\n",
    "\n",
    "And here's our vector output version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import backend as K\n",
    "import tensorflow\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Seed the RNGs\n",
    "np.random.seed(42)\n",
    "tensorflow.set_random_seed(42)\n",
    "\n",
    "# Custom R2 metric (courtesy of https://www.kaggle.com/c/mercedes-benz-greener-manufacturing/discussion/34019)\n",
    "def r2_score(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "# Input shape\n",
    "input_shape = (X_tr.shape[1],)\n",
    "\n",
    "# Both outputs at the same time\n",
    "max_epochs = 50\n",
    "\n",
    "# Define a Neural Network model to predict the number of infected\n",
    "model = Sequential()\n",
    "model.add(Dense(16, activation='relu', input_shape=input_shape))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(2, activation='linear'))\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mse',\n",
    "              metrics=[r2_score])\n",
    "\n",
    "# Setup and perform training\n",
    "weight_fname = os.path.join('shared', 'nn_reg.h5')\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=5),\n",
    "             ModelCheckpoint(filepath=weight_fname, monitor='val_loss', save_best_only=True)]\n",
    "model.fit(X_tr, Y_tr, epochs=max_epochs, batch_size=32, callbacks=callbacks,\n",
    "          validation_data=(X_vl, Y_vl), verbose=0)\n",
    "\n",
    "# Save the model architecture\n",
    "arch_fname = os.path.join('shared', 'nn_reg.json')\n",
    "with open(arch_fname, 'w') as fp:\n",
    "    fp.write(model.to_json())\n",
    "\n",
    "# Evaluate on the test set\n",
    "res_tr = model.evaluate(X_tr, Y_tr, batch_size=len(X_tr))\n",
    "print('Loss and R2 on the training set: {}, {}'.format(*res_tr))\n",
    "res_vl = model.evaluate(X_vl, Y_vl, batch_size=len(X_vl))\n",
    "print('Loss and R2 on the validation set: {}, {}'.format(*res_vl) )\n",
    "res_ts = model.evaluate(X_ts, Y_ts, batch_size=len(X_ts))\n",
    "print('Loss and R2 on the test set: {}, {}'.format(*res_ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even better!\n",
    "\n",
    "In principle we should do something about the overfitting. Actually, it is mostly due to the reduced size of the validation and the test sets, so generating more data should be the way to go.\n",
    "\n",
    "For now, let's just move to the next step: we will train a different Machine Learning model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
